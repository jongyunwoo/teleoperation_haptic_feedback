{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b376c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# --- helper 함수들 ---\n",
    "#회전 행렬 만들기\n",
    "#x축으로 roll, y축으로 pitch, z축으로 yaw\n",
    "def rpy_to_mat(roll, pitch, yaw): \n",
    "    \n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, math.cos(roll), -math.sin(roll)],\n",
    "                   [0, math.sin(roll),  math.cos(roll)]])\n",
    "    Ry = np.array([[ math.cos(pitch), 0, math.sin(pitch)],\n",
    "                   [0, 1, 0],\n",
    "                   [-math.sin(pitch), 0, math.cos(pitch)]])\n",
    "    Rz = np.array([[math.cos(yaw), -math.sin(yaw), 0],\n",
    "                   [math.sin(yaw),  math.cos(yaw), 0],\n",
    "                   [0, 0, 1]])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "\n",
    "def axis_angle_to_mat(axis, angle):\n",
    "    axis = np.array(axis) / np.linalg.norm(axis) #단위 벡터로 만들기\n",
    "    x,y,z = axis #축을 x,y,z로 나누기\n",
    "    c, s = math.cos(angle), math.sin(angle) #삼각함수 각도 구하기\n",
    "    C = 1-c #1-cos 저장\n",
    "    # Rodrigues 회전 공식 적용\n",
    "    return np.array([\n",
    "      [x*x*C + c,   x*y*C - z*s, x*z*C + y*s],\n",
    "      [y*x*C + z*s, y*y*C + c,   y*z*C - x*s],\n",
    "      [z*x*C - y*s, z*y*C + x*s, z*z*C + c  ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4e23534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_middle_1\n",
      "Left arm end-effector position in world frame: [ 0.46655618 -0.13741504  0.05557407]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urchin import URDF\n",
    "\n",
    "ROOT_PATH = '/home/scilab/Documents/teleoperation/avp_teleoperate/teleop/utils/datanalysis/episode_0001'\n",
    "# 1. URDF와 data.json 파일 경로\n",
    "URDF_PATH   = '/home/scilab/Documents/teleoperation/avp_teleoperate/assets/g1_inspire_hand_description/g1_29dof_rev_1_0_with_inspire_hand_FTP.urdf'    # URDF가 담긴 .txt 파일\n",
    "DATA_PATH   = '/home/scilab/Documents/teleoperation/avp_teleoperate/teleop/utils/datanalysis/episode_0001/data.json'   # data.json 파일\n",
    "\n",
    "\n",
    "finger_map = {'thumb':5, 'thumb2':4, 'index':3, 'middle':2, 'ring':1, 'pinky':0}\n",
    "\n",
    "LEFTRIGHT = 'right'\n",
    "WHICH_FINGER = 'middle'\n",
    "FRAME = 0\n",
    "\n",
    "names = [LEFTRIGHT, 'shoulder', 'elbow', 'wrist', 'pitch', 'roll', 'yaw']   #얘는 list로 비교하면서 바꿨고 (아래 for i, joint in enumerate(joints) 부분에서)\n",
    "handmap = {\n",
    "                f'k{LEFTRIGHT.capitalize()}HandThumbRotation' : f'{LEFTRIGHT}_thumb_1_joint',\n",
    "                f'k{LEFTRIGHT.capitalize()}HandThumbBend' : f'{LEFTRIGHT}_thumb_3_joint',\n",
    "                f'k{LEFTRIGHT.capitalize()}HandIndex' : f'{LEFTRIGHT}_index_1_joint',\n",
    "                f'k{LEFTRIGHT.capitalize()}HandMiddle' : f'{LEFTRIGHT}_middle_1_joint',\n",
    "                f'k{LEFTRIGHT.capitalize()}HandRing' : f'{LEFTRIGHT}_ring_1_joint',\n",
    "                f'k{LEFTRIGHT.capitalize()}HandPinky' : f'{LEFTRIGHT}_little_1_joint',\n",
    "            }\n",
    "\n",
    "# 2. URDF 로드\n",
    "robot = URDF.load(URDF_PATH, lazy_load_meshes=True)\n",
    "\n",
    "# 3. data.json 로드\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "joints  = data['info']['joint_names'][f'{LEFTRIGHT}_arm']  # 7개 joint names list       여기부터\n",
    "\n",
    "for i, joint in enumerate(joints):\n",
    "    tmp_name = \"\"\n",
    "\n",
    "    joint = joint[1:]\n",
    "    for name in names:\n",
    "        find_res = joint.lower().find(name)\n",
    "        if find_res == -1:\n",
    "            continue\n",
    "        else:\n",
    "            tmp_name = tmp_name + joint[:find_res+len(name)] + '_'\n",
    "            joint = joint[find_res+len(name):]\n",
    "    \n",
    "    joints[i] = (tmp_name[:-1] + '_joint').lower()\n",
    "\n",
    "# 4. idx=0의 left_arm 관절각(qpos)과 joint 이름 목록 가져오기\n",
    "qpos    = data['data'][FRAME]['states'][f'{LEFTRIGHT}_arm']['qpos']                         #여기까지는 arm을 뽑는부분\n",
    "\n",
    "hand_qpos  = data['data'][FRAME]['states'][f'{LEFTRIGHT}_hand']['qpos']                 #여기부터\n",
    "hand_joints = data['info']['joint_names'][f'{LEFTRIGHT}_hand']\n",
    "hand_joints = [handmap[x] for x in hand_joints]                                       #여기까지는 hand joints 정리해두는부분 이중에 한개만 뽑아서 넣을거임\n",
    "\n",
    "# 5. joint name → angle 매핑\n",
    "q_dict = {name: angle for name, angle in zip(joints, qpos)}\n",
    "\n",
    "q_dict[hand_joints[finger_map[WHICH_FINGER]]] = hand_qpos[finger_map[WHICH_FINGER]]       #hand q_dict에 추가\n",
    "\n",
    "# 6. forward kinematics 계산  \n",
    "# ee_link = f'{LEFTRIGHT}_wrist_yaw_link'     # wrist뽑을때 uncomment, hand 뽑을때 comment\n",
    "ee_link = hand_joints[finger_map[WHICH_FINGER]][:-6]                    # hand 뽑을때 uncomment, wrist 뽑을때 comment\n",
    "print(ee_link)\n",
    "# link_fk()는 각 링크별로 월드 기준 4×4 변환행렬을 반환\n",
    "fk = robot.link_fk(q_dict)\n",
    "# for link_obj, T in fk.items():\n",
    "#     print(link_obj.name)\n",
    "# T_ee_world = fk[ee_link]   # (4,4) 행렬\n",
    "ee_link_obj  = robot.link_map[ee_link]    # 이름→Link 객체 얻기\n",
    "T_ee_world   = fk[ee_link_obj]                 # 올바르게 인덱싱!\n",
    "\n",
    "# 7. 위치(translation) 추출\n",
    "pos_ee_world = T_ee_world[:3, 3]\n",
    "print('Left arm end-effector position in world frame:', pos_ee_world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Left wrist position in D435 camera frame: [ 0.55214511 -0.15494504  0.04958988]\n"
     ]
    }
   ],
   "source": [
    "# cam = robot['d435I_joint']\n",
    "T_world_cam = np.eye(4)\n",
    "T_world_cam[:3,:3] = rpy_to_mat(0, 0.8307767239493009, 0)\n",
    "T_world_cam[:3, 3] = [0.0576235, 0.01753, 0.42987]   # :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "\n",
    "# 5) camera→left_wrist 변환\n",
    "T_cam_ee = np.linalg.inv(T_world_cam) @ T_ee_world\n",
    "\n",
    "# 6) translation 성분이 바로 “카메라 기준” 손끝 좌표\n",
    "pos_cam_ee = T_cam_ee[:3, 3]\n",
    "print(\"Left wrist position in D435 camera frame:\", pos_cam_ee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadee9b",
   "metadata": {},
   "source": [
    "0프레임 :[ 0.46655618 -0.13741504  0.05557407]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ecb11e",
   "metadata": {},
   "source": [
    "0프레임 :   [0.22070608 0.18346118 0.01026804] 이게 맨처음 정지위치쯤 이때 위치가 이렇다는건 일단 허리쪽이 0,0,0인건 확실히 맞긴한듯?\n",
    "\n",
    "카메라기준 : [ 0.41982428  0.16593118 -0.1625094 ] \n",
    "\n",
    "roll일때: [ 0.16308258 -0.19796951 -0.40547137]\n",
    "\n",
    "-----\n",
    "\n",
    "50프레임 : [0.29628327 0.1957955  0.08448675] 위로만 올렸을때\n",
    "\n",
    "카메라기준 : [ 0.41597896  0.1782655  -0.05665317]\n",
    "\n",
    "roll일때 : [ 0.23865977 -0.13484525 -0.36453386]\n",
    "\n",
    "------\n",
    "\n",
    "143프레임 : [0.35340309 0.20754136 0.17797557] 이게 0보다 살짝왼쪽, 꽤 위, 꽤 앞\n",
    "\n",
    "카메라기준 : [0.38545768 0.19001136 0.048567  ]\n",
    "\n",
    "roll일때 : [ 0.29577959 -0.05788768 -0.31016792]\n",
    "\n",
    "------\n",
    "\n",
    "285프레임 : [0.3584677  0.18067249 0.18189677] 이게 143이랑 높이는 비슷하고..가 아니라 다 비슷한게 맞음\n",
    "\n",
    "카메라기준 : [0.38597712 0.16314249 0.05495107]\n",
    "\n",
    "------\n",
    "\n",
    "405프레임 : [0.33813684 0.20274944 0.1394626 ] 약간 인사하는거같은 손위치. x는 비슷한거같고(살~짝 오른쪽?), y는 좀더 뒤로왔고, z는 거의 비슷한듯\n",
    "\n",
    "카메라기준 : [0.40360371 0.18521944 0.01132417]\n",
    "\n",
    "roll일때 : [ 0.28051334 -0.08955899 -0.33259869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27656ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520.5732963707565 177.50040585950345\n",
      "(327, 302)\n",
      "596\n",
      "Saved to projected_point.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1) Intrinsics\n",
    "width, height = 848, 480\n",
    "fx = 426.7954\n",
    "fy = 426.7954\n",
    "cx = width  / 2  # 424\n",
    "cy = height / 2  # 320\n",
    "\n",
    "# 2) pos_cam_ee: (X, Y, Z)  \n",
    "#    X: 오른쪽(+), Y: 카메라 앞쪽(+), Z: 위쪽(+)\n",
    "print(pos_cam_ee)\n",
    "Xc =  pos_cam_ee[0]      \n",
    "Yc =  pos_cam_ee[1]      \n",
    "Zc =   pos_cam_ee[2]     \n",
    "\n",
    "# 2) 투영\n",
    "u = fx * (Yc / Xc) + cx\n",
    "v = fy * (Zc / Xc) + cy\n",
    "\n",
    "# 소수점→정수 픽셀 좌표\n",
    "print(u,v)\n",
    "pt = (int(round(848-u)), int(round(480-v)))\n",
    "print(pt)\n",
    "# 4) 이미지 읽고 표시  \n",
    "img = cv2.imread(\"/home/scilab/Documents/teleoperation/avp_teleoperate/teleop/utils/datanalysis/episode_0001/colors/000596_color_0.jpg\")\n",
    "print(FRAME)\n",
    "if img is None:\n",
    "    raise RuntimeError(\"Unable to load image.\")\n",
    "cv2.circle(img, pt, 8, (255,0,0), thickness=-1)  # 빨간 점\n",
    "cv2.putText(img, f\"{pt}\", (pt[0]+10, pt[1]),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "\n",
    "# 5) 결과 저장 (Jupyter에서 imshow 대신)\n",
    "cv2.imwrite(f\"projected_pointindex2{FRAME}.png\", img)\n",
    "print(\"Saved to projected_point.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62068785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jyteleop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
